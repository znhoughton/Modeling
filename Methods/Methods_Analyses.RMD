---
title: "Methods Writeup"
author: "Zach Houghton"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message = F}
library(tidyverse)
library(brms)
library(gridExtra)
library(kableExtra)
```

## Methods

### Does the number of modeling events affect spontaneous button presses?

First let's load in our data:

```{r message = F}

data = read_csv("export_09_23_2022.csv")

```

Hypothesis 1: Does modelling predict button pressing?

We will use a mixed effects model to test whether more modelling events by the owner lead to more button presses by the dog. The model equation will be as follows:

Dog Presses \~ Modelling Events \* Concept + (1 + Modelling Events \* Concept \| Subject)

In order to test this, however, we will need to organize our data such that for each button for each subject, we have a column for the number of modeling events and a column for the number of spontaneous button presses.

First, we need to decide what criteria constitutes a modeling event. Obviously, any is_human == TRUE is a modeling event. Additionally, any events which are labeled as "modeling" in the context columns are as well.

Additionally, we'll exclude button presses that are accidental or experimental presses.

We're also going to calculate each dogs earliest recorded interaction:

```{r}
data = data %>%
  group_by(unique_id) %>%
  arrange(occurred_at) %>%
  mutate(first_recorded_press = first(occurred_at))
```

```{r}
data2 = data

data2$contexts = tolower(data2$contexts) #convert all characters to lower
  
data2 = data2 %>%
  filter(!grepl('accident|study', contexts))

data2 = data2 %>%
  mutate(modeling_event = ifelse(grepl('model', contexts)|is_human == TRUE, 1, 0))

data3 = data2 %>%
  mutate(modeling_event = ifelse(is_human == TRUE, 1, 0))

```

Before we proceed, let's exclude subjects with less than 200 interactions.

```{r}

#data2 = data2 %>%
  #group_by(pusher_id) %>%
  #mutate(number_interactions = length(unique(interaction_id)))

data2 = data2 %>%
  group_by(pusher_id) %>%
  filter(length(interactions_count) > 200)

data2$learner_type = tolower(data2$learner_type)

data2 = data2 %>%
  filter(learner_type == 'dog' | is_human == TRUE)

data3 = data3 %>%
  group_by(pusher_id) %>%
  filter(length(interactions_count) > 200)

data3$learner_type = tolower(data3$learner_type)

data3 = data3 %>%
  filter(learner_type == 'dog' | is_human == TRUE)

#length(unique(data2$pusher_id))

```

Next we need to select the columns we actually need, then collapse across buttons across subjects to get one row for each button per subject. That is, we want one row for all the 'OUTSIDE' buttons for subject 1, with a column for the number of spontaneous button presses and a column for the number of modeling events.

```{r}

data2 = data2 %>%
  select(pusher_id, household_id, interaction_id, is_human, press_id, concept, button_id, n_buttons_in_interaction, contexts, press_order, modeling_event)

data3 = data3 %>%
  select(pusher_id, household_id, interaction_id, is_human, press_id, concept, button_id, n_buttons_in_interaction, contexts, press_order, button_introduced_at, modeling_event)

```

Count the number of learners in each household (i.e., number of pusher_ids that are is_human == FALSE) This was done because it isn't noted in the data who the owner is modeling the event towards. Thus we used households with only one learner.

```{r message = F}

household_learner_data = data2 %>%
  group_by(household_id) %>%
  filter(is_human == FALSE) %>%
  mutate(number_of_learners = length(unique(pusher_id))) %>%
  select(household_id, number_of_learners) %>%
  group_by(household_id) %>%
  filter(row_number()==1) %>%
  left_join(data2)
  
household_learner_data2 = data3 %>%
  group_by(household_id) %>%
  filter(is_human == FALSE) %>%
  mutate(number_of_learners = length(unique(pusher_id))) %>%
  select(household_id, number_of_learners) %>%
  group_by(household_id) %>%
  filter(row_number()==1) %>%
  left_join(data3)
  
household_learner_data = household_learner_data %>%
  filter(number_of_learners == 1)

household_learner_data2 = household_learner_data2 %>%
  filter(number_of_learners == 1)


```

Next we'll group_by pusher_id and button_id and collapse across rows, summing the number of modeling events. We'll also mutate another column which is just going to sum across the number of modeling_events == 0 (i.e., number of spontaneous button presses).

```{r message = F}

question1_data = household_learner_data %>%
  group_by(household_id, button_id, concept) %>%
  summarize(num_modeling_events = sum(modeling_event), num_spont_button_press = sum(modeling_event == 0))

question1_data2 = household_learner_data2 %>%
  group_by(household_id, button_id, concept) %>%
  summarize(num_modeling_events = sum(modeling_event), num_spont_button_press = sum(modeling_event == 0))


```

We'll also exclude rows with 0 modeling_events recorded.

```{r}

question1_data = question1_data %>%
  filter(!num_modeling_events==0)

question1_data2 = question1_data2 %>%
  filter(!num_modeling_events==0)


```

#### Plotting

Before we go any further, let's look at a scatterplot of our data to see what we might expect to get from our models:

```{r}

plot1 = ggplot(question1_data, aes(x = num_modeling_events, y = num_spont_button_press)) + 
  geom_point(size = 1) +
  theme_bw()

plot2 = ggplot(question1_data2, aes(x = num_modeling_events, y = num_spont_button_press)) + 
  geom_point(size = 1) +
  theme_bw()

grid.arrange(plot1,plot2, nrow = 1)

question1_data_no60 = question1_data %>%
  filter(household_id != 60)

plot3 = ggplot(question1_data_no60, aes(x = num_modeling_events, y = num_spont_button_press)) + 
  geom_point(size = 1) +
  theme_bw()

plot3

grid.arrange(plot1, plot3, nrow = 1)

question1_data_model30 = question1_data %>%
  filter(num_modeling_events > 30)

plot4 = ggplot(question1_data_model30, aes(x = num_modeling_events, y = num_spont_button_press)) + 
  geom_point(size = 1) +
  theme_bw() +
  xlab('Number of Modeling Events') +
  ylab('Number of Spontaneous Button Presses')

plot4
```

#### Model

Now let's run our model:

Note that the model is simplified a bit from the pre-registered version. Specifically, I've dropped by-item intercepts and I dropped the by-household slopes. Both were dropped due to convergence issues.

```{r}
options(contrasts = c("contr.sum","cont.sum"))  #sum coding

model_modeling = bf(num_spont_button_press ~ num_modeling_events + (1 + num_modeling_events | household_id), family = negbinomial())

model_modeling = brm(data = question1_data, formula = model_modeling,
             iter = 10000,
             cores = 4,
             chains = 4,
             thin = 4,
             warmup = 5000,
             control = list(max_treedepth = 11,  adapt_delta = 0.99), 
             init = '0',
             seed = 45689,
             #normalize = FALSE,
             #backend = 'cmdstanr',
             file = 'model_modeling'
             #prior = priors
             )

model_modeling
```

For negative binomial models, the coefficient represents the difference in log odds for a one-unit change in our independent variable. Since our coefficient for the number of modeling events is 0.01, then every additional one-unit change in modeling events results in a percentage increase of our response variable equal to `(exp(0.01) - 1) * 100`.

In other words, for every additional modeling event, there is a `r (exp(0.01) - 1) * 100`% increase in number of spontaneous button presses. While this is statistically significant, it is such a small increase that it is mostly meaningless.

### Two-button combinations

The goal of this section is to analyze the app data to determine if there are combinations that are universally frequent, and if individual dogs have combinations that they prefer. To do so, we'll be using a liner regression with a negative binomial distribution (which is used for skewed count data).

We need to manipulate our data such that each row contains an interaction, with concept1, concept2, etc as different columns.

To clean this up, let's discard modeling data (is_human == TRUE) and single-button presses (n_interactions == 1) and only select the columns we need:

pusher_id, concept, interaction_id, n_buttons_in_interaction

```{r}
 
question2_data = data2 %>%
  filter(is_human == FALSE  & n_buttons_in_interaction > 1)

question2_data = question2_data %>%
  select(pusher_id, concept, interaction_id, n_buttons_in_interaction, press_order) %>%
  group_by(interaction_id) %>%
  filter(!any(duplicated(press_order)))
 
 
```

```{r}

question2_data2 = question2_data %>%
  pivot_wider(
    names_from = press_order,
    values_from = concept
  )

write_csv(question2_data2, "two_combo_data_for_python.csv")

```

We'll use a Python script to get this into the proper format for analysis.

```{r message = F}

question2_data_from_py = read_csv("two_combo_data.csv")

```

Next thing we need to do is get the relative frequencies of each word:

```{r}

data_rel_probs_w1 = data %>%
  count(pusher_id, concept) %>%
  group_by(pusher_id) %>%
  mutate(rel_probs_w1 = n / sum(n)) %>%
  rename(word1 = concept)

data_rel_probs_w2 = data %>%
  count(pusher_id, concept) %>%
  group_by(pusher_id) %>%
  mutate(rel_probs_w2 = n / sum(n)) %>%
  rename(word2 = concept)

```

Counting number of combinations by order, courtesy of this post: <https://stackoverflow.com/questions/51429631/count-combinations-by-column-order-doesnt-matter>

```{r}


question2_data_from_py = question2_data_from_py %>% #drop rows where word1 == word2
  filter(!(word1==word2))

question2_data_from_py = question2_data_from_py %>%
  left_join(data_rel_probs_w1, by = c('pusher_id', 'word1')) %>%
  left_join(data_rel_probs_w2, by = c('pusher_id', 'word2'))

question2_data = question2_data_from_py %>%
  group_by(pusher_id) %>%
  count(combination_id = str_c(pmin(word1, word2), ' - ', pmax(word1, word2)), name = 'combination_freq', combination_rel_probs = rel_probs_w1 * rel_probs_w2)
 
question2_data$combination_id = question2_data$combination_id %>%
  str_replace_all(pattern = " ", replace = "") %>%
  str_replace_all(pattern = "-", replace = "_")

#question2_data$pusher_id = as.character(question2_data$pusher_id)

question2_data = question2_data %>%
  rename(subject = pusher_id)
 
```

Lastly, we will take the buttons that are shared across the most subjects and examine the combinations. We did this for two reasons:

-   Computationally easier to run.

-   There's a large number of variability across dogs with respect to what buttons they have.

```{r}
question2_data2 = data2 %>% #concepts that are present in more than half the groups
  group_by(concept) %>%
  mutate(shared = n_distinct(pusher_id)) %>% #== n_distinct(.$pusher_id)) 
  filter(shared >= 157)
  
most_used_concepts = unique(question2_data2$concept)
  
question2_data_from_py2 = question2_data_from_py %>%
  filter(word1 %in% most_used_concepts & word2 %in% most_used_concepts)

question2_data_from_py2 = question2_data_from_py2 %>% #drop rows where word1 == word2
  filter(!(word1==word2))

question3_data = question2_data_from_py2 %>%
  group_by(pusher_id) %>%
  count(combination_id = str_c(pmin(word1, word2), ' - ', pmax(word1, word2)), name = 'combination_freq', combination_rel_probs = rel_probs_w1 * rel_probs_w2)
 
 
question3_data$combination_id = question3_data$combination_id %>%
  str_replace_all(pattern = " ", replace = "") %>%
  str_replace_all(pattern = "-", replace = "_")

question3_data$pusher_id = as.character(question3_data$pusher_id)

question3_data = question3_data %>%
  rename(subject = pusher_id)
 
```

And voila, our data is in a format that we can start analyzing. Let's review what our model will be:

combination frequency \~ combination ID + (1 + combination ID \| subject)

A quick graph of our data though (top 5 largest two-word combos):

#### Plotting

```{r message = F}
top_n_rows = 10
question2_plot = question2_data %>%
  ungroup() %>%
  arrange(desc(combination_freq)) %>%
  slice(1:top_n_rows)

ggplot(question2_plot, aes(x = combination_id, y = combination_freq)) + 
  geom_point(size = 1) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 65, hjust = 1))

```

#### Model

We'll be using a negative binomial model with the following equation:

combination_freq \~ combination_id \* combination_rel_probs + (1 + combination_id \* combination_rel_probs \| subject)

```{r}
options(contrasts = c("contr.sum","cont.sum"))  #sum coding
options(mc.cores = parallel::detectCores())

combo_model = brm(combination_freq ~ combination_id + offset(combination_rel_probs) + (1 + combination_id + offset(combination_rel_probs) | subject),  #1 + combination_id | subject
             data = question3_data,
             family = negbinomial(),
             iter = 4000,
             cores = 4,
             chains = 4,
             warmup = 2000,
             thin = 4,
             #backend = 'cmdstanr',
             control = list(max_treedepth = 12, adapt_delta = 0.99),
             init = '0',
             #seed = 1,
             file = 'combo_model2.4'
             #prior = priors
             )

fixef(combo_model)
```

##### Interpretation:

We can interpret the largest coefficient value of 0.75 as follows: On average, the combination labeled as "OWNNAME_PERSON_PARENT" increases the expected value of the frequency of the combination by `exp(0.75) * 100`%. In other words, when our dependent variable is "OWNNAME_PERSON_PARENT", we expect the number of combinations to be `r round((exp(0.75) - 1) * 100, 3)`% greater than if our dependent variable was some other combination.

Let's create a key to help make the results interpretable. BRMS uses factoring to determine the levels and the naming scheme, so we can create a key that converts the various levels to their original concept name.

```{r}
key = as.data.frame(levels(factor(question3_data$combination_id)))
colnames(key) = 'ID'

coefs = as.data.frame(fixef(combo_model))
coefs_no_intercept = coefs[-1,] %>%
  add_row(Estimate = -sum(coefs[-1,1]))

coefs_no_intercept$key = key$ID
coefs_key = coefs %>%
  full_join(coefs_no_intercept)

row.names(coefs_key) = c(row.names(coefs), 'combination_id105')

coefs_key = coefs_key %>%
  rename('combination' = 'key')

coefs_key = as.data.frame(coefs_key)

coefs_key = coefs_key %>%
  select(combination, Estimate, Est.Error, Q2.5, Q97.5) %>%
  arrange(desc(Estimate))


head(coefs_key, 10)

```

Here's the full table with estimates:

```{r, echo = F}
coefs_key = coefs_key %>%
  rename(Combination = combination)

coefs_key_table = coefs_key[,2:5]

rownames(coefs_key_table) = c('Intercept', coefs_key[2:nrow(coefs_key_table),1])

kable(coefs_key_table, format = 'html') %>%
  kable_styling() %>%
  column_spec(1, bold = T)
```
